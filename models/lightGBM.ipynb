{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c9995e-0a61-40d6-aafc-760f8b12db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a175a6e-b64d-47e8-944a-594116499615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/Processed/XGBoost_Dataset.v2_trimmed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe21b9b-d04f-4f3b-85e1-cb4a9927bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zh/vm69w9xx2dz7lj6rxj4mc08r0000gn/T/ipykernel_64042/3069182216.py:46: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  chunk[\"date\"] = pd.to_datetime(chunk[\"date\"], errors=\"coerce\", dayfirst=dayfirst)\n",
      "/var/folders/zh/vm69w9xx2dz7lj6rxj4mc08r0000gn/T/ipykernel_64042/3069182216.py:46: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  chunk[\"date\"] = pd.to_datetime(chunk[\"date\"], errors=\"coerce\", dayfirst=dayfirst)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/Processed/XGBoost_Dataset.v2_trimmed.parquet (dropped column: dist)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "def csv_to_parquet_chunked_drop_col10(\n",
    "    csv_path,\n",
    "    out_path=None,\n",
    "    *,\n",
    "    chunksize=1_000_000,\n",
    "    dayfirst=True,           # used in explicit to_datetime below\n",
    "    force_date_as=\"datetime\",# \"datetime\" or \"string\"\n",
    "    compression=\"snappy\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert CSV -> Parquet in chunks, dropping column at positional index 10 (0-based),\n",
    "    and forcing a consistent dtype for 'date' across all chunks.\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "    out_path = Path(out_path) if out_path else csv_path.with_suffix(\".parquet\")\n",
    "    if out_path.suffix.lower() != \".parquet\":\n",
    "        out_path = out_path.with_suffix(\".parquet\")\n",
    "\n",
    "    # Read header to build usecols excluding index 10\n",
    "    header_cols = pd.read_csv(csv_path, nrows=0).columns.tolist()\n",
    "    # keep all except the 11th column\n",
    "    if len(header_cols) > 10:\n",
    "        usecols = [c for i, c in enumerate(header_cols) if i != 10]\n",
    "        dropped = header_cols[10]\n",
    "    else:\n",
    "        usecols = header_cols\n",
    "        dropped = None\n",
    "\n",
    "    writer = None\n",
    "    for chunk in pd.read_csv(\n",
    "        csv_path,\n",
    "        chunksize=chunksize,\n",
    "        usecols=usecols,     # <-- exclude problematic column at read time\n",
    "        low_memory=False     # consistent dtype inference within a chunk\n",
    "        # no parse_dates here; we convert explicitly below\n",
    "    ):\n",
    "        # Force consistent 'date' dtype every chunk\n",
    "        if \"date\" in chunk.columns:\n",
    "            if force_date_as == \"datetime\":\n",
    "                # convert in-place; invalid parses -> NaT\n",
    "                chunk[\"date\"] = pd.to_datetime(chunk[\"date\"], errors=\"coerce\", dayfirst=dayfirst)\n",
    "            elif force_date_as == \"string\":\n",
    "                chunk[\"date\"] = chunk[\"date\"].astype(\"string\")\n",
    "            else:\n",
    "                raise ValueError(\"force_date_as must be 'datetime' or 'string'\")\n",
    "\n",
    "        # (Optional) ensure identical column order each chunk\n",
    "        chunk = chunk[usecols]\n",
    "\n",
    "        table = pa.Table.from_pandas(chunk, preserve_index=False)\n",
    "        if writer is None:\n",
    "            writer = pq.ParquetWriter(out_path, table.schema, compression=compression)\n",
    "        writer.write_table(table)\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "\n",
    "    msg = f\"Wrote: {out_path}\"\n",
    "    if dropped:\n",
    "        msg += f\" (dropped column: {dropped})\"\n",
    "    return msg\n",
    "\n",
    "# Example usage\n",
    "print(csv_to_parquet_chunked_drop_col10(\n",
    "    csv_path=\"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/Processed/XGBoost_Dataset.v2_trimmed.csv\",\n",
    "    out_path=\"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/Processed/XGBoost_Dataset.v2_trimmed.parquet\",\n",
    "    dayfirst=True,\n",
    "    force_date_as=\"datetime\"   # or \"string\" if you prefer keeping it textual\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edab04-dfc2-47cc-b37d-bbd3a9af68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maybe include margin, and res_place in the racers as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "084e7bcd-e8d6-492d-9b97-e215523004e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example: your dataframe has a column 'country_code'\n",
    "df['countryCode'] = df['countryCode'].astype('category')\n",
    "df['headGear'] = df['headGear'].astype('category')\n",
    "df['prev_headgear'] = df['prev_headgear'].astype('category')\n",
    "df['course_clean'] = df['course_clean'].astype('category')\n",
    "df['course_surface'] = df['course_surface'].astype('category')\n",
    "df['track_layout'] = df['track_layout'].astype('category')\n",
    "df['race_jump_type'] = df['race_jump_type'].astype('category')\n",
    "df['best_dist_band_hist'] = df['best_dist_band_hist'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1f69dd3-a829-47ea-b85c-c90b4029cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessarycolumns = ['rid',\n",
    "    'horseName','age','saddle','isFav','trainerName',\n",
    "    'jockeyName','position','positionL',\n",
    "    'weightSt','weightLb','RPR','TR','OR',\n",
    "    'father','mother','gfather','runners',\n",
    "    'margin','res_place','time','band_bins',\n",
    "    'condition','hurdles','rclass','course',\n",
    "    'prizes','winningTime','metric','source_year',\n",
    "    'prev_raceId','close_finish','date2','title','saddle_rank_bin',\n",
    "    'band_clean','band','ages','days_since_last_race_binned',\n",
    "    'distance_banding','decimalPrice','race_age_band',\n",
    "    'previous_trainer','previous_jockey']\n",
    "\n",
    "df = df.drop(columns=unnecessarycolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d269c0e4-573c-4adf-bb68-28a011abd47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1997, 2000, 2001, 2013, 2011, 2012, 2002, 2010, 2016, 2017, 2018,\n",
       "       2005, 2003, 2004, 2014, 1998, 2009, 2006, 2007, 2008, 2019, 2015,\n",
       "       1999])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19d9e3bd-c686-4797-a30f-75e7f3ccfad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = df[df['year'] <= 2014]\n",
    "val_data = df[(df['year'] < 2018) & (df['year'] > 2014)]\n",
    "cal_data = df[df['year'] == 2018]\n",
    "bkt_data = df[df['year'] == 2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "474b1974-8643-4681-a145-1be4fff0560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data = tr_data.copy().sort_values('date')\n",
    "val_data = val_data.copy().sort_values('date')\n",
    "cal_date = cal_data.copy().sort_values('date')\n",
    "bkt_data = bkt_data.copy().sort_values('date')\n",
    "\n",
    "tr_data = tr_data.drop(columns='date')\n",
    "val_data = val_data.drop(columns='date')\n",
    "cal_data = cal_data.drop(columns='date')\n",
    "bkt_data = bkt_data.drop(columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eefe68b0-a53c-41d7-841b-951019e36740",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_y = tr_data['res_win']\n",
    "tr_data_p = tr_data['betting_prob_win']\n",
    "tr_data_x = tr_data.drop(columns=['res_win','betting_prob_win'])\n",
    "\n",
    "val_data_y = val_data['res_win']\n",
    "val_data_p = val_data['betting_prob_win']\n",
    "val_data_x = val_data.drop(columns=['res_win','betting_prob_win'])\n",
    "\n",
    "cal_data_y = cal_data['res_win']\n",
    "cal_data_p = cal_data['betting_prob_win']\n",
    "cal_data_x = cal_data.drop(columns=['res_win','betting_prob_win'])\n",
    "\n",
    "bkt_data_y = bkt_data['res_win']\n",
    "bkt_data_p = bkt_data['betting_prob_win']\n",
    "bkt_data_x = bkt_data.drop(columns=['res_win','betting_prob_win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec979c6-18c8-4731-b57e-54143edbbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ========= 1) SMALL, STRATIFIED SAMPLES (speed!) =========\n",
    "def stratified_sample(X, y, frac=0.10, seed=42):\n",
    "    \"\"\"Return a stratified subset of rows (~frac of each class).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pos_idx = y[y == 1].index\n",
    "    neg_idx = y[y == 0].index\n",
    "    n_pos = max(1, int(len(pos_idx) * frac))\n",
    "    n_neg = max(1, int(len(neg_idx) * frac))\n",
    "    pick_pos = rng.choice(pos_idx, n_pos, replace=False)\n",
    "    pick_neg = rng.choice(neg_idx, n_neg, replace=False)\n",
    "    idx = np.concatenate([pick_pos, pick_neg])\n",
    "    return X.loc[idx], y.loc[idx]\n",
    "\n",
    "# tune on 5–10% for speed; also shrink validation during tuning\n",
    "X_tune, y_tune = stratified_sample(tr_data_x, tr_data_y, frac=0.10, seed=42)\n",
    "X_val_tune, y_val_tune = stratified_sample(val_data_x, val_data_y, frac=0.10, seed=123)\n",
    "\n",
    "# keep categorical col list consistent\n",
    "cat_cols = [c for c in X_tune.columns if str(X_tune[c].dtype) == 'category']\n",
    "\n",
    "# ========= 2) BASE PARAMS (fast) + SMALL SEARCH SPACE =========\n",
    "base = dict(\n",
    "    objective='binary',\n",
    "    n_estimators=1000,                # small cap; early stopping will halt earlier\n",
    "    learning_rate=0.07,               # faster per-tree progress for tuning\n",
    "    max_bin=127,                      # cheaper histograms\n",
    "    bin_construct_sample_cnt=200_000, # speed up binning\n",
    "    force_col_wise=True,              # faster for many features\n",
    "    first_metric_only=True,           # early stopping focuses on first metric\n",
    "    boosting_type='gbdt',             # (fast) Gradient-based One-Side Sampling\n",
    "    top_rate=0.2, other_rate=0.1,     # GOSS params\n",
    "    n_jobs=-1,\n",
    "    #max_cat_to_onehot=0               # use partition-bas\n",
    "    ed categorical handling\n",
    ")\n",
    "\n",
    "space = {\n",
    "    \"num_leaves\":              [31, 63, 127],\n",
    "    \"min_data_in_leaf\":        [150, 300, 500],\n",
    "    \"min_sum_hessian_in_leaf\": [1.0, 5.0, 10.0],\n",
    "    \"feature_fraction\":        [0.6, 0.75, 0.9],\n",
    "    \"feature_fraction_bynode\": [0.6, 0.8, 0.9],\n",
    "    \"bagging_fraction\":        [0.8, 0.9],    # ignored by GOSS (harmless to keep)\n",
    "    \"bagging_freq\":            [1],\n",
    "    \"lambda_l1\":               [0.0, 1.0, 3.0],\n",
    "    \"lambda_l2\":               [0.0, 3.0, 8.0],\n",
    "    \"min_gain_to_split\":       [0.0, 0.05]\n",
    "}\n",
    "\n",
    "def pick(rng, d):  # random sampler for the small search space\n",
    "    return {k: rng.choice(v) for k, v in d.items()}\n",
    "\n",
    "# ========= 3) QUICK RANDOM SEARCH (6–10 trials) =========\n",
    "rng = np.random.default_rng(777)\n",
    "best = {\"logloss\": 1e9, \"auc\": None, \"params\": None, \"iters\": None, \"secs\": None}\n",
    "\n",
    "for i in range(8):  # try 6–10 quick configs\n",
    "    params = {**base, **pick(rng, space)}\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.fit(\n",
    "        X_tune, y_tune,\n",
    "        eval_set=[(X_val_tune, y_val_tune)],\n",
    "        eval_metric=['binary_logloss', 'auc'],  # first one used for early stopping\n",
    "        categorical_feature=cat_cols,\n",
    "        callbacks=[lgb.early_stopping(80), lgb.log_evaluation(200)]\n",
    "    )\n",
    "    secs = time.time() - t0\n",
    "\n",
    "    ll  = model.best_score_['valid_0']['binary_logloss']\n",
    "    auc = model.best_score_['valid_0']['auc']\n",
    "    it  = model.best_iteration_\n",
    "\n",
    "    print(f\"[Trial {i+1:02d}] ll={ll:.6f} auc={auc:.6f} iters={it} time={secs:.1f}s params={params}\")\n",
    "\n",
    "    if ll < best[\"logloss\"]:\n",
    "        best.update({\"logloss\": ll, \"auc\": auc, \"params\": params, \"iters\": it, \"secs\": secs})\n",
    "\n",
    "print(\"\\n=== BEST ON TUNE SUBSET ===\")\n",
    "print(f\"LogLoss={best['logloss']:.6f} | AUC={best['auc']:.6f} | iters={best['iters']} | time={best['secs']:.1f}s\")\n",
    "print(\"Params:\", best[\"params\"])\n",
    "\n",
    "# ========= 4) REFIT BEST ON FULL TRAIN (proper settings) =========\n",
    "# Switch back to standard GBDT, lower LR, larger n_estimators; keep structure regs from best\n",
    "final_params = {**best[\"params\"]}\n",
    "final_params.update(dict(\n",
    "    boosting_type='gbdt',   # standard boosting for best accuracy\n",
    "    learning_rate=0.02,     # safer LR\n",
    "    n_estimators=5000,      # rely on early stopping\n",
    "    first_metric_only=False # log both metrics nicely\n",
    "))\n",
    "\n",
    "final = lgb.LGBMClassifier(**final_params)\n",
    "final.fit(\n",
    "    tr_data_x, tr_data_y,\n",
    "    eval_set=[(val_data_x, val_data_y)],\n",
    "    eval_metric=['binary_logloss', 'auc'],\n",
    "    categorical_feature=cat_cols,\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(200)]\n",
    ")\n",
    "\n",
    "print(\"\\n=== REFIT ON FULL TRAIN ===\")\n",
    "print(\"Val logloss:\", final.best_score_['valid_0']['binary_logloss'])\n",
    "print(\"Val AUC:\",     final.best_score_['valid_0']['auc'])\n",
    "print(\"Best iteration:\", final.best_iteration_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e75324-beb7-421b-abeb-81e431446328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "best_params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,     # make sure 'binary_logloss' is first in eval_metric\n",
    "    'learning_rate': 0.07,         # from your best-on-subset\n",
    "    'n_estimators': 5000,          # ceiling; rely on early stopping(200)\n",
    "    'num_leaves': 31,\n",
    "    'max_bin': 127,\n",
    "    'bin_construct_sample_cnt': 200000,  # alias of subsample_for_bin\n",
    "    'min_data_in_leaf': 300,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'feature_fraction': 0.6,       # alias of colsample_bytree\n",
    "    'feature_fraction_bynode': 0.8,\n",
    "    'bagging_fraction': 0.8,       # alias of subsample\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 1.0,\n",
    "    'lambda_l2': 8.0,\n",
    "    'min_gain_to_split': 0.05,\n",
    "    'force_col_wise': True,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "modelv1 = lgb.LGBMClassifier(**best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e2cd13-667f-4cde-8863-3a4f5a08d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90281d81-9c6e-45ed-ae67-ebde33bbe8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 234985, number of negative: 2268018\n",
      "[LightGBM] [Info] Total Bins 18485\n",
      "[LightGBM] [Info] Number of data points in the train set: 2503003, number of used features: 204\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.093881 -> initscore=-2.267140\n",
      "[LightGBM] [Info] Start training from score -2.267140\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.272471\n",
      "[200]\tvalid_0's binary_logloss: 0.266604\n",
      "[300]\tvalid_0's binary_logloss: 0.263844\n",
      "[400]\tvalid_0's binary_logloss: 0.262204\n",
      "[500]\tvalid_0's binary_logloss: 0.261147\n",
      "[600]\tvalid_0's binary_logloss: 0.260356\n",
      "[700]\tvalid_0's binary_logloss: 0.259777\n",
      "[800]\tvalid_0's binary_logloss: 0.259513\n",
      "[900]\tvalid_0's binary_logloss: 0.259065\n",
      "[1000]\tvalid_0's binary_logloss: 0.258681\n",
      "[1100]\tvalid_0's binary_logloss: 0.258445\n",
      "[1200]\tvalid_0's binary_logloss: 0.257957\n",
      "[1300]\tvalid_0's binary_logloss: 0.257662\n",
      "[1400]\tvalid_0's binary_logloss: 0.257574\n",
      "[1500]\tvalid_0's binary_logloss: 0.25745\n",
      "[1600]\tvalid_0's binary_logloss: 0.257336\n",
      "[1700]\tvalid_0's binary_logloss: 0.257201\n",
      "[1800]\tvalid_0's binary_logloss: 0.257076\n",
      "[1900]\tvalid_0's binary_logloss: 0.256969\n",
      "[2000]\tvalid_0's binary_logloss: 0.256876\n",
      "[2100]\tvalid_0's binary_logloss: 0.256768\n",
      "[2200]\tvalid_0's binary_logloss: 0.25668\n",
      "[2300]\tvalid_0's binary_logloss: 0.256555\n",
      "[2400]\tvalid_0's binary_logloss: 0.256499\n",
      "[2500]\tvalid_0's binary_logloss: 0.256452\n",
      "[2600]\tvalid_0's binary_logloss: 0.256393\n",
      "[2700]\tvalid_0's binary_logloss: 0.256267\n",
      "[2800]\tvalid_0's binary_logloss: 0.2562\n",
      "[2900]\tvalid_0's binary_logloss: 0.256191\n",
      "[3000]\tvalid_0's binary_logloss: 0.256074\n",
      "[3100]\tvalid_0's binary_logloss: 0.255889\n",
      "[3200]\tvalid_0's binary_logloss: 0.255915\n",
      "[3300]\tvalid_0's binary_logloss: 0.255815\n",
      "[3400]\tvalid_0's binary_logloss: 0.255805\n",
      "[3500]\tvalid_0's binary_logloss: 0.255793\n",
      "[3600]\tvalid_0's binary_logloss: 0.255793\n",
      "[3700]\tvalid_0's binary_logloss: 0.255763\n",
      "[3800]\tvalid_0's binary_logloss: 0.255781\n",
      "[3900]\tvalid_0's binary_logloss: 0.25574\n",
      "[4000]\tvalid_0's binary_logloss: 0.255673\n",
      "[4100]\tvalid_0's binary_logloss: 0.255673\n",
      "Early stopping, best iteration is:\n",
      "[3982]\tvalid_0's binary_logloss: 0.255667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=1,\n",
       "               bin_construct_sample_cnt=200000, feature_fraction=0.6,\n",
       "               feature_fraction_bynode=0.8, first_metric_only=True,\n",
       "               force_col_wise=True, lambda_l1=1.0, lambda_l2=8.0,\n",
       "               learning_rate=0.07, max_bin=127, min_data_in_leaf=300,\n",
       "               min_gain_to_split=0.05, min_sum_hessian_in_leaf=10.0,\n",
       "               n_estimators=5000, n_jobs=-1, objective=&#x27;binary&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=1,\n",
       "               bin_construct_sample_cnt=200000, feature_fraction=0.6,\n",
       "               feature_fraction_bynode=0.8, first_metric_only=True,\n",
       "               force_col_wise=True, lambda_l1=1.0, lambda_l2=8.0,\n",
       "               learning_rate=0.07, max_bin=127, min_data_in_leaf=300,\n",
       "               min_gain_to_split=0.05, min_sum_hessian_in_leaf=10.0,\n",
       "               n_estimators=5000, n_jobs=-1, objective=&#x27;binary&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=1,\n",
       "               bin_construct_sample_cnt=200000, feature_fraction=0.6,\n",
       "               feature_fraction_bynode=0.8, first_metric_only=True,\n",
       "               force_col_wise=True, lambda_l1=1.0, lambda_l2=8.0,\n",
       "               learning_rate=0.07, max_bin=127, min_data_in_leaf=300,\n",
       "               min_gain_to_split=0.05, min_sum_hessian_in_leaf=10.0,\n",
       "               n_estimators=5000, n_jobs=-1, objective='binary')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv1.fit(\n",
    "    tr_data_x, tr_data_y,\n",
    "    eval_set=[(val_data_x, val_data_y)],\n",
    "    eval_metric='logloss',                    # or 'auc'\n",
    "    categorical_feature=[c for c in tr_data_x.columns if str(tr_data_x[c].dtype)=='category'],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=200), lgb.log_evaluation(100)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "430f9bf8-2d08-4eb2-b455-29cac19d7c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n"
     ]
    }
   ],
   "source": [
    "val_preds = modelv1.predict_proba(val_data_x, num_iteration=modelv1.best_iteration_)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f45cd-ed05-459c-a90e-832397682d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Score on full dataset\n",
    "Logloss: 0.257044\n",
    "\n",
    "AUC: 0.818583\n",
    "\n",
    "Best iteration: 5000 trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d038a5a-4082-41e1-927e-fc4aeaf2e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def blend_logloss_from_csv(model, X_valid, y_valid,\n",
    "                           p_cat_csv_path=\"/content/p_cat_valid.csv\",\n",
    "                           id_col=None, x_id_col=None, p_cat_col=\"p_cat\",\n",
    "                           alpha=0.5, return_preds=False):\n",
    "    \"\"\"\n",
    "    Blend CatBoost probs from CSV with LightGBM probs and compute log loss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : fitted LightGBM model (e.g., LGBMClassifier) with predict_proba\n",
    "    X_valid : DataFrame or array of validation features\n",
    "    y_valid : array-like of 0/1 labels for validation set\n",
    "    p_cat_csv_path : path to CSV containing a column with p_cat probabilities\n",
    "    id_col : optional column name in the CSV to align on (e.g., 'rid')\n",
    "    x_id_col : optional column name in X_valid with the same IDs for alignment\n",
    "    p_cat_col : name of the p_cat column in the CSV (default 'p_cat')\n",
    "    alpha : weight for LightGBM in the blend; blend = alpha*LGBM + (1-alpha)*Cat\n",
    "    return_preds : if True, also return a DataFrame of y, p_lgb, p_cat, p_blend\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics : dict with logloss_lgbm, logloss_cat, logloss_blend, alpha\n",
    "    (optionally) df_out : DataFrame of predictions if return_preds=True\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(p_cat_csv_path)\n",
    "\n",
    "    # Align p_cat to X_valid\n",
    "    if id_col is not None and x_id_col is not None:\n",
    "        if hasattr(X_valid, \"columns\") and x_id_col in X_valid.columns and id_col in df.columns:\n",
    "            key = pd.Series(X_valid[x_id_col]).astype(df[id_col].dtype)\n",
    "            aligned = df.set_index(id_col).reindex(key.values)\n",
    "            p_cat = aligned[p_cat_col].to_numpy()\n",
    "        else:\n",
    "            raise ValueError(\"ID alignment requested, but id_col/x_id_col not found in data.\")\n",
    "    else:\n",
    "        if len(df) != len(X_valid):\n",
    "            raise ValueError(f\"Row mismatch: CSV has {len(df)}, X_valid has {len(X_valid)}.\"\n",
    "                             \" Provide id_col and x_id_col to align by ID.\")\n",
    "        p_cat = df[p_cat_col].to_numpy()\n",
    "\n",
    "    # LightGBM probabilities (handle best_iteration if present)\n",
    "    best_iter = getattr(model, \"best_iteration_\", None) or getattr(model, \"best_iteration\", None)\n",
    "    try:\n",
    "        p_lgb = model.predict_proba(X_valid, num_iteration=best_iter)[:, 1]\n",
    "    except TypeError:\n",
    "        p_lgb = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    y = np.asarray(y_valid)\n",
    "    p_blend = alpha * p_lgb + (1.0 - alpha) * p_cat\n",
    "\n",
    "    metrics = {\n",
    "        \"logloss_lgbm\": float(log_loss(y, p_lgb)),\n",
    "        \"logloss_cat\": float(log_loss(y, p_cat)),\n",
    "        \"logloss_blend\": float(log_loss(y, p_blend)),\n",
    "        \"alpha\": float(alpha),\n",
    "    }\n",
    "\n",
    "    if return_preds:\n",
    "        df_out = pd.DataFrame({\n",
    "            \"y_valid\": y,\n",
    "            \"p_lgb\": p_lgb,\n",
    "            \"p_cat\": p_cat,\n",
    "            \"p_blend\": p_blend\n",
    "        })\n",
    "        return metrics, df_out\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bc1c782-1d80-4a98-8afc-fd609fd16d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "{'logloss_lgbm': 0.2556668354091641, 'logloss_cat': 0.37358610522068186, 'logloss_blend': 0.27825962655935865, 'alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Equal-weight blend; CSV at /content/p_cat_valid.csv with column 'p_cat'\n",
    "metrics, preds = blend_logloss_from_csv(\n",
    "    model=modelv1,\n",
    "    X_valid=val_data_x,\n",
    "    y_valid=val_data_y,\n",
    "    p_cat_csv_path=\"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Models/p_cat_valid.csv\",\n",
    "    # If both the CSV and X have an ID column (e.g., 'rid'), uncomment these:\n",
    "    # id_col=\"rid\", x_id_col=\"rid\",\n",
    "    alpha=0.5,\n",
    "    return_preds=True\n",
    ")\n",
    "\n",
    "print(metrics)          # shows logloss_lgbm, logloss_cat, logloss_blend\n",
    "#preds.to_csv(\"/content/p_blend_valid.csv\", index=False)  # optional: save blended preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19bd4f22-8456-471c-a25f-2c42a1619d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBM is significantly better: Saving the model \n",
    "import joblib, json\n",
    "\n",
    "# 1) Save the sklearn model\n",
    "joblib.dump(modelv1, \"lgbm_model.pkl\")\n",
    "\n",
    "# 2) Save useful metadata\n",
    "best_iter = getattr(modelv1, \"best_iteration_\", None) or getattr(modelv1, \"best_iteration\", None)\n",
    "feature_names = list(tr_data_x.columns)  # or val_data_x.columns if that’s your schema\n",
    "json.dump(\n",
    "    {\"feature_names\": feature_names, \"best_iteration\": best_iter},\n",
    "    open(\"lgbm_meta.json\",\"w\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc2c64c8-bfa2-4e82-8cae-758f50cf2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "import joblib, json, pandas as pd\n",
    "\n",
    "modelv1 = joblib.load(\"lgbm_model.pkl\")\n",
    "meta = json.load(open(\"lgbm_meta.json\"))\n",
    "feat = meta[\"feature_names\"]; best_iter = meta[\"best_iteration\"]\n",
    "\n",
    "# enforce same columns/order at inference\n",
    "def enforce_schema(df, cols):\n",
    "    df2 = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in df2:\n",
    "            df2[c] = 0\n",
    "    return df2[cols]\n",
    "\n",
    "#X_new = enforce_schema(new_data[feat], feat)\n",
    "#p = modelv1.predict_proba(X_new, num_iteration=best_iter)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "399b02e9-0572-40ff-b290-6fe4e45f53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n"
     ]
    }
   ],
   "source": [
    "val_preds = modelv1.predict_proba(val_data_x, num_iteration=modelv1.best_iteration_)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efda2ec4-8bc4-43d4-a66b-0d5a4b2a71e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2135759259.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[24], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"logloss_lgbm\",  float(log_loss(val_data_y, val_preds)),\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "print(\"logloss_lgbm\",  float(log_loss(val_data_y, val_preds)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80007fed-73d0-413d-8204-b791066dc7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bin_construct_sample_cnt is set=200000, subsample_for_bin=200000 will be ignored. Current value: bin_construct_sample_cnt=200000\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.0\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.05, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.05\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=10.0, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=10.0\n",
      "LogLoss raw : 0.25196757919955537\n",
      "LogLoss cal : 0.2594468125440462\n",
      "Brier  raw  : 0.07141700988564263\n",
      "Brier  cal  : 0.07249725890663117\n",
      "AUC raw/cal : 0.8169778887473813 0.8169778887473813\n"
     ]
    }
   ],
   "source": [
    "#Now Calibrating either using Platt Scaling/Isotonic\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss, brier_score_loss, roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "cal = CalibratedClassifierCV(modelv1, method=\"sigmoid\", cv=\"prefit\")  # or \"sigmoid\"\n",
    "cal.fit(cal_data_x, cal_data_y)\n",
    "\n",
    "# 3) evaluate/backtest on 2019\n",
    "best_iter = getattr(modelv1, \"best_iteration_\", None) or getattr(modelv1, \"best_iteration\", None)\n",
    "p_raw = modelv1.predict_proba(bkt_data_x, num_iteration=best_iter)[:, 1]\n",
    "p_cal = cal.predict_proba(bkt_data_x)[:, 1]\n",
    "\n",
    "print(\"LogLoss raw :\", log_loss(bkt_data_y, p_raw))\n",
    "print(\"LogLoss cal :\", log_loss(bkt_data_y, p_cal))\n",
    "print(\"Brier  raw  :\", brier_score_loss(bkt_data_y, p_raw))\n",
    "print(\"Brier  cal  :\", brier_score_loss(bkt_data_y, p_cal))\n",
    "print(\"AUC raw/cal :\", roc_auc_score(bkt_data_y, p_raw), roc_auc_score(bkt_data_y, p_cal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37b7e6f1-1161-4b58-b3f0-78c93d296128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss raw  : 0.25196757919955537\n",
      "LogLoss iso  : 0.25168979880523923\n",
      "Brier  raw   : 0.07141700988564263\n",
      "Brier  iso   : 0.07140390456700967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "def fit_isotonic(p_cal, y_cal):\n",
    "    iso = IsotonicRegression(y_min=1e-12, y_max=1-1e-12, out_of_bounds=\"clip\")\n",
    "    iso.fit(p_cal, y_cal)\n",
    "    return iso\n",
    "\n",
    "iso = fit_isotonic(val_preds, val_data_y)\n",
    "p19_iso = iso.transform(p_raw)\n",
    "\n",
    "print(\"LogLoss raw  :\", log_loss(bkt_data_y, p_raw))\n",
    "print(\"LogLoss iso  :\", log_loss(bkt_data_y, p19_iso))\n",
    "print(\"Brier  raw   :\", brier_score_loss(bkt_data_y, p_raw))\n",
    "print(\"Brier  iso   :\", brier_score_loss(bkt_data_y, p19_iso))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b05821a9-6950-4246-88b5-8dcba607f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkt_preds = iso.transform(p_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9408b0-fcd5-42e2-a507-6dc224f64484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e94544d2-8533-410c-aeb6-e6aba32e3c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def backtesting_strategy_kelly_safe(\n",
    "    pred_probs,\n",
    "    market_probs,\n",
    "    results,\n",
    "    min_edge=0.0,\n",
    "    market_inflation=1.0,\n",
    "    starting_bankroll=1000.0,\n",
    "    kelly_fraction_cap=0.5,     # half-Kelly default\n",
    "    commission=0.0,             # e.g., 0.02 for 2%\n",
    "    min_mkt_prob=1e-4,          # ignore probs below this (~odds > 10,000 if 1e-4)\n",
    "    max_dec_odds=200.0,         # cap odds to avoid numeric blow-ups\n",
    "    eps_b=1e-6                   # protect when o ~ 1.0 (b = o-1 tiny)\n",
    "):\n",
    "    df = pd.DataFrame({\n",
    "        \"pred\": np.asarray(pred_probs, dtype=float),\n",
    "        \"mkt\" : np.asarray(market_probs, dtype=float),\n",
    "        \"res\" : np.asarray(results, dtype=float),\n",
    "    })\n",
    "\n",
    "    # Clean & adjust\n",
    "    df[\"pred\"] = df[\"pred\"].clip(0.0, 1.0)\n",
    "    df[\"mkt\"]  = df[\"mkt\"] * float(market_inflation)\n",
    "    # Keep only sensible market probs\n",
    "    valid = np.isfinite(df[\"mkt\"]) & (df[\"mkt\"] > min_mkt_prob) & (df[\"mkt\"] < 1.0 - min_mkt_prob)\n",
    "\n",
    "    # Decimal odds (cap)\n",
    "    df[\"dec_odds\"] = np.where(valid, 1.0 / df[\"mkt\"], np.nan)\n",
    "    df.loc[df[\"dec_odds\"] > max_dec_odds, \"dec_odds\"] = np.nan  # drop extreme odds\n",
    "    valid &= np.isfinite(df[\"dec_odds\"])\n",
    "\n",
    "    # Edge & Kelly fraction\n",
    "    df[\"edge\"] = df[\"pred\"] - df[\"mkt\"]\n",
    "    b = df[\"dec_odds\"] - 1.0\n",
    "    # Avoid divide-by-near-zero where b ~ 0 (odds ~ 1)\n",
    "    safe = valid & (b.abs() >= eps_b) & (df[\"edge\"] > float(min_edge))\n",
    "\n",
    "    raw_f = pd.Series(0.0, index=df.index, dtype=float)\n",
    "    raw_f.loc[safe] = (df.loc[safe, \"pred\"] * df.loc[safe, \"dec_odds\"] - 1.0) / b.loc[safe]\n",
    "    raw_f.replace([np.inf, -np.inf], 0.0, inplace=True)\n",
    "    raw_f = raw_f.clip(lower=0.0)              # Kelly = 0 if EV ≤ 0\n",
    "    f = raw_f.clip(upper=float(kelly_fraction_cap))\n",
    "    df[\"kelly_frac\"] = np.where(safe, f, 0.0)\n",
    "\n",
    "    # Sequential bankroll simulation\n",
    "    bankroll = float(starting_bankroll)\n",
    "    bank_hist, stake_hist, pnl_hist, bet_hist = [], [], [], []\n",
    "\n",
    "    for i, r in df.iterrows():\n",
    "        frac = float(r[\"kelly_frac\"])\n",
    "        if frac <= 0.0 or not np.isfinite(frac):\n",
    "            bet_hist.append(0); stake_hist.append(0.0); pnl_hist.append(0.0); bank_hist.append(bankroll); continue\n",
    "        o = float(r[\"dec_odds\"])\n",
    "        if not np.isfinite(o):\n",
    "            bet_hist.append(0); stake_hist.append(0.0); pnl_hist.append(0.0); bank_hist.append(bankroll); continue\n",
    "\n",
    "        stake_amt = bankroll * frac\n",
    "        # Win/loss PnL (net of commission if any)\n",
    "        net_win = (o - 1.0) * stake_amt * (1.0 - float(commission))\n",
    "        pnl = net_win if r[\"res\"] == 1.0 else -stake_amt\n",
    "        \n",
    "        bankroll += pnl\n",
    "        bet_hist.append(1)\n",
    "        stake_hist.append(stake_amt)\n",
    "        pnl_hist.append(pnl)\n",
    "        bank_hist.append(bankroll)\n",
    "\n",
    "    df[\"bet\"] = bet_hist\n",
    "    df[\"stake_amt\"] = stake_hist\n",
    "    df[\"PnL\"] = pnl_hist\n",
    "    df[\"bankroll\"] = bank_hist\n",
    "    print(df['PnL'])\n",
    "    # Metrics (NaN-safe)\n",
    "    n_bets = int(np.nansum(df[\"bet\"]))\n",
    "    total_staked = float(np.nansum(df[\"stake_amt\"]))\n",
    "    total_pnl = float(np.nansum(df[\"PnL\"]))\n",
    "    hit_rate = float(df.loc[df[\"bet\"] == 1, \"res\"].mean()) if n_bets else 0.0\n",
    "    avg_kelly = float(df.loc[df[\"bet\"] == 1, \"kelly_frac\"].mean()) if n_bets else 0.0\n",
    "    roi_per_bet = (total_pnl / total_staked) if total_staked > 0 else 0.0\n",
    "\n",
    "    bk = pd.Series(bank_hist, dtype=float)\n",
    "    peak = bk.cummax()\n",
    "    drawdown = bk - peak\n",
    "    max_dd = float(drawdown.min())\n",
    "    max_dd_pct = float((drawdown / peak).min()) if peak.max() > 0 else 0.0\n",
    "\n",
    "    summary = {\n",
    "        \"bets\": n_bets,\n",
    "        \"total_staked\": total_staked,\n",
    "        \"total_PnL\": total_pnl,\n",
    "        \"final_bankroll\": float(bankroll),\n",
    "        \"ROI_per_bet\": roi_per_bet,\n",
    "        \"hit_rate_on_bets\": hit_rate,\n",
    "        \"avg_kelly_fraction\": avg_kelly,\n",
    "        \"max_drawdown\": max_dd,\n",
    "        \"max_drawdown_pct\": max_dd_pct,\n",
    "        \"total_possible_bets\": int(len(df)),\n",
    "        \"commission\": float(commission),\n",
    "        \"guards\": f\"min_mkt_prob={min_mkt_prob}, max_dec_odds={max_dec_odds}, eps_b={eps_b}\",\n",
    "    }\n",
    "\n",
    "    return df, summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a5fa25e-cb33-44bd-be03-d23986f2f7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0.000000e+00\n",
      "1         0.000000e+00\n",
      "2         0.000000e+00\n",
      "3         0.000000e+00\n",
      "4         0.000000e+00\n",
      "              ...     \n",
      "171844    0.000000e+00\n",
      "171845    0.000000e+00\n",
      "171846    6.545502e+34\n",
      "171847    0.000000e+00\n",
      "171848    0.000000e+00\n",
      "Name: PnL, Length: 171849, dtype: float64\n",
      "{'bets': 25670, 'total_staked': 2.9904559431540077e+37, 'total_PnL': 8.780000648705472e+35, 'final_bankroll': 8.78000064870546e+35, 'ROI_per_bet': 0.02936007356605723, 'hit_rate_on_bets': 0.15247370471367355, 'avg_kelly_fraction': 0.04848372178120209, 'max_drawdown': -4.384184056200234e+36, 'max_drawdown_pct': -0.9999902601844763, 'total_possible_bets': 171849, 'commission': 0.0, 'guards': 'min_mkt_prob=0.001, max_dec_odds=200.0, eps_b=1e-06'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_k, summary = backtesting_strategy_kelly_safe(\n",
    "    bkt_preds, bkt_data_p, bkt_data_y,\n",
    "    min_edge=0.00,\n",
    "    market_inflation=1.8,\n",
    "    starting_bankroll=1,\n",
    "    kelly_fraction_cap=0.1,\n",
    "    commission=0.0,\n",
    "    min_mkt_prob=1e-3,     # try 1e-3 first (odds ≤ 1000)\n",
    "    max_dec_odds=200.0,    # cap payouts at 200x\n",
    ")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a86a47f0-078f-481d-a6ed-29eb4c6ef7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you already have df returned from your backtest\n",
    "# Plot cumulative PnL\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(np.log(df_k[\"PnL\"].cumsum()), label=\"Cumulative PnL\", linewidth=2)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\", alpha=0.7)\n",
    "plt.title(\"Cumulative PnL Over Bets\")\n",
    "plt.xlabel(\"Bet number\")\n",
    "plt.ylabel(\"Cumulative PnL\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b621668-6310-4ab7-9562-59c00f3bb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def backtesting_strategy_fixed(\n",
    "    pred_probs,          # model probs in [0,1]\n",
    "    decimal_odds,        # actual decimal odds offered\n",
    "    results,             # 0/1 outcomes\n",
    "    stake=1.0,\n",
    "    min_edge=0.0\n",
    "):\n",
    "    pred_probs = np.asarray(pred_probs, dtype=float)\n",
    "    decimal_odds = np.asarray(decimal_odds, dtype=float)\n",
    "    results = np.asarray(results, dtype=int)\n",
    "\n",
    "    # sanity checks\n",
    "    assert pred_probs.shape == decimal_odds.shape == results.shape\n",
    "    assert np.all((pred_probs >= 0) & (pred_probs <= 1))\n",
    "\n",
    "    # raw implied prob from odds (no normalisation!)\n",
    "    p_mkt = 1.0 / decimal_odds\n",
    "\n",
    "    # edge = model - market implied prob\n",
    "    edge = pred_probs - p_mkt\n",
    "\n",
    "    # bet selection\n",
    "    mask = edge >= min_edge\n",
    "    n_bets = int(mask.sum())\n",
    "    total_staked = n_bets * stake\n",
    "\n",
    "    # PnL with decimal odds\n",
    "    win_payout = (decimal_odds - 1.0) * stake\n",
    "    pnl = np.where(results == 1, win_payout, -stake)\n",
    "    total_pnl = float(pnl[mask].sum())\n",
    "\n",
    "    # metrics\n",
    "    roi_per_bet = (total_pnl / total_staked) if total_staked > 0 else 0.0\n",
    "    hit_rate = float(results[mask].mean()) if n_bets else 0.0\n",
    "    avg_edge = float(edge[mask].mean()) if n_bets else 0.0\n",
    "\n",
    "    summary = {\n",
    "        \"bets\": n_bets,\n",
    "        \"total_staked\": float(total_staked),\n",
    "        \"total_PnL\": total_pnl,\n",
    "        \"ROI_per_bet\": roi_per_bet,\n",
    "        \"hit_rate_on_bets\": hit_rate,\n",
    "        \"avg_edge_on_bets\": avg_edge,\n",
    "        \"total_possible_bets\": int(len(pred_probs)),\n",
    "    }\n",
    "    bkt_df = pd.DataFrame({\n",
    "        \"pred\": pred_probs, \"odds\": decimal_odds, \"p_mkt\": p_mkt,\n",
    "        \"edge\": edge, \"bet\": mask.astype(int),\n",
    "        \"result\": results, \"pnl\": pnl\n",
    "    })\n",
    "    return bkt_df, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4d05414-3479-4b8f-9ced-afe1b821ba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    171849.000000\n",
      "mean         22.857245\n",
      "std          31.782141\n",
      "min           1.040000\n",
      "25%           6.100000\n",
      "50%          12.000000\n",
      "75%          26.000000\n",
      "max         566.000000\n",
      "Name: betting_prob_win, dtype: float64\n",
      "count    171849.000000\n",
      "mean          0.120026\n",
      "std           0.118543\n",
      "min           0.001767\n",
      "25%           0.038462\n",
      "50%           0.083333\n",
      "75%           0.163934\n",
      "max           0.961538\n",
      "Name: betting_prob_win, dtype: float64\n",
      "{'bets': 12353, 'total_staked': 12353.0, 'total_PnL': 19785.097535242552, 'ROI_per_bet': 1.60164312598094, 'hit_rate_on_bets': 0.3681696753824982, 'avg_edge_on_bets': 0.26666279712968105, 'total_possible_bets': 171849}\n"
     ]
    }
   ],
   "source": [
    "bkt_df, summary = backtesting_strategy_fixed(\n",
    "    pred_probs=bkt_preds,\n",
    "    decimal_odds=bkt_data_decimal, \n",
    "    results=bkt_data_y,\n",
    "    stake=1.0,\n",
    "    min_edge=0.1\n",
    ")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111229a9-4d88-4530-abec-2d7355318e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
