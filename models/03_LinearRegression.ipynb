{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "939c0ccb-60ca-4eb4-a674-ec78abec1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23fdaa26-042a-44d2-b2b4-b3c29cf2e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zh/vm69w9xx2dz7lj6rxj4mc08r0000gn/T/ipykernel_81804/4218471939.py:1: DtypeWarning: Columns (9,27,37,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/Processed/full_feature_engineered_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/Processed/full_feature_engineered_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6c062329-a6f3-43f8-b568-9f4d9056801d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'saddle', 'isFav', 'overWeight', 'outHandicap', 'RPR', 'TR',\n",
       "       'OR', 'weight', 'res_win',\n",
       "       ...\n",
       "       'jump_flat', 'jump_hurdles', 'jump_chase', 'age_juvenile',\n",
       "       'age_open_all', 'age_mixed', 'age_open_young', 'age_young_only',\n",
       "       'age_veteran', 'age_unknown'],\n",
       "      dtype='object', length=130)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5fab231b-b6ae-484f-abeb-8962c1e32bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'horse_course_winrate', \n",
    "    'horse_jumptype_win_Rate', \n",
    "    'horse_rclass_win_Rate', \n",
    "    'horse_distanceband_win_Rate', \n",
    "    'horse_class_win_Rate',\n",
    "    'horse_coursesurface_win_Rate', \n",
    "    'horse_saddlerankbin_win_Rate', \n",
    "    'horse_bandbin_win_Rate', \n",
    "    \n",
    "    'jockey_jumptype_win_Rate',\n",
    "    'jockey_course_win_Rate', \n",
    "    'horse_jockey_win_Rate',\n",
    "    'jockey_distanceband_winrate', \n",
    "    \n",
    "    'trainer_course_win_Rate', \n",
    "    'trainer_jumptype_win_Rate',\n",
    "    'trainer_class_winrate', \n",
    "    'trainer_saddlerankbin_winrate',\n",
    "    \n",
    "    'father_course_winrate', \n",
    "    'father_jumptype_winrate', \n",
    "    'father_distanceband_winrate', \n",
    "    'father_coursesurface_winrate', \n",
    "    'father_class_winrate', \n",
    "    'father_band_winrate',\n",
    "    \n",
    "    'mother_course_winrate', \n",
    "    'mother_jumptype_winrate', \n",
    "    \n",
    "    'gfather_course_winrate', \n",
    "    'gfather_jumptype_winrate', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "463439df-5426-4539-850e-8c52156fc9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_path = \"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/Processed/\"\n",
    "#df['key'] = df['date'].astype(str) + '_' + df['horseName'].astype(str)\n",
    "\n",
    "#for feat in features:\n",
    "#    feat_df = pd.read_csv(f\"{save_path}/{feat}.csv\")\n",
    "    \n",
    "#    # Fix: drop or aggregate duplicates\n",
    "#    if feat_df['key'].duplicated().any():\n",
    "#        print(f\"WARNING: {feat} has duplicated keys. Deduplicating...\")\n",
    "#        feat_df = feat_df.groupby('key').mean(numeric_only=True).reset_index()\n",
    "#\n",
    "#    df = df.merge(feat_df, on='key', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "990d350e-ec49-4d1d-b479-2d4aded4635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = pd.concat([df['res_win'],df['res_place']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36d08453-f1a6-442c-9552-30eb85d6415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Make sure ages column is string and handle NaNs\n",
    "ages_clean = df['ages'].fillna('').astype(str)\n",
    "\n",
    "# Extract min and max ages using vectorized regex\n",
    "df['race_min_age'] = ages_clean.str.extract(r'(\\d+)', expand=False).astype(float)\n",
    "df['race_max_age'] = ages_clean.str.extract(r'-(\\d+)', expand=False).astype(float)\n",
    "\n",
    "# Handle patterns like '3yo+' (no upper limit → leave max as NaN)\n",
    "is_plus = ages_clean.str.contains(r'yo\\+')\n",
    "\n",
    "# Handle patterns like '4yo' (single age = min and max are equal)\n",
    "is_single = ages_clean.str.match(r'^\\d+yo$')\n",
    "df.loc[is_single, 'race_max_age'] = df.loc[is_single, 'race_min_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db78640e-0199-417d-a54b-904c1ca19b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_band_category(row):\n",
    "    min_age, max_age = row['race_min_age'], row['race_max_age']\n",
    "\n",
    "    if pd.isna(min_age):\n",
    "        return 'unknown'\n",
    "\n",
    "    if max_age is not np.nan:\n",
    "        if max_age <= 3:\n",
    "            return 'juvenile'      # 2–3yo only\n",
    "        elif max_age <= 5:\n",
    "            return 'young_only'   # e.g., 3-5yo\n",
    "    if min_age >= 6:\n",
    "        return 'veteran'          # 6yo+, 7yo+, etc.\n",
    "    elif min_age <= 3 and np.isnan(max_age):\n",
    "        return 'open_young'       # e.g., 3yo+\n",
    "    elif np.isnan(max_age):\n",
    "        return 'open_all'         # 4yo+, 5yo+, etc.\n",
    "    \n",
    "    return 'mixed'\n",
    "\n",
    "df['race_age_band'] = df.apply(age_band_category, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "614f544e-3f6b-4c4e-baa3-0c511af0dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns needed for regression \n",
    "unnecessary_columns = ['rid','horseName','decimalPrice','trainerName',\n",
    "                 'jockeyName','position','dist','weightSt','weightLb',\n",
    "                 'father','mother','gfather','runners',\n",
    "                'weightSt','weightLb','headGear','father',\n",
    "                'mother','gfather','course','band','ages',\n",
    "                'hurdles','prizes','countryCode','source_year',\n",
    "                'prev_raceId','band_clean','close_finish','year',\n",
    "                'res_place','prev_headgear','course_clean','margin']\n",
    "#Original Index   \n",
    "#Key\n",
    "\n",
    "df = df.drop(columns=unnecessary_columns,axis=1)\n",
    "\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9bae1fd-4cd6-4537-bee5-8bc7338736da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_toomany_nans = [col for col in df.columns if df[col].isna().sum() > 1000]\n",
    "df[[f\"{col}_nan\" for col in cols_with_toomany_nans]] = df[cols_with_toomany_nans].isna().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d4de2526-2585-48d6-9bc6-98d8a1662105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "efb1c1f2-a0d0-448f-8791-288488699f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rclassmapping = {\n",
    "    'Class 1':1,\n",
    "    'Class 2':2,\n",
    "    'Class 3':3,\n",
    "    'Class 4':4,\n",
    "    'Class 5':5,\n",
    "    'Class 6':6,\n",
    "    'Class 7':7,}\n",
    "    \n",
    "df['rclass'] = df['rclass'].map(rclassmapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f2a3e4c9-7ba0-46c3-a205-41422ac34cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mapping = {\n",
    "    'Firm': 1,\n",
    "    'Good To Firm': 2,\n",
    "    'Good': 3,\n",
    "    'Good To Yielding': 4,\n",
    "    'Yielding': 5,\n",
    "    'Yielding To Soft': 6,\n",
    "    'Good To Soft': 7,\n",
    "    'Soft': 8,\n",
    "    'Soft To Heavy': 9,\n",
    "    'Heavy': 10,\n",
    "    'Very Soft': 11,\n",
    "    'Holding': 12,\n",
    "    'Hard': 13,\n",
    "    'Fast': 14,\n",
    "    'Slow': 15,\n",
    "    'Standard To Fast': 16,\n",
    "    'Standard': 17,\n",
    "    'Standard To Slow': 18,\n",
    "    'Sloppy': 19,\n",
    "    'Muddy': 20,\n",
    "    'Frozen': 21,\n",
    "    'Abandoned': 22\n",
    "}\n",
    "\n",
    "df['condition'] = df['condition'].map(condition_mapping).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d283927-fa07-4183-9b6e-8fa9403084e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_bins_mapping = {\n",
    "    '≤60':1,\n",
    "    '61-75':2,\n",
    "    '76-90':3,\n",
    "    '91-105':4,\n",
    "    '106-120':5,\n",
    "    '121-140':6,\n",
    "    '141-175':7}\n",
    "\n",
    "df['band_bins'] = df['band_bins'].map(band_bins_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7949d21c-7111-4c3e-a544-208b1fb7b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncond_mapping = {\n",
    "    'Hard':-1,\n",
    "    '0':0,\n",
    "    '1':1,\n",
    "    '2':2,\n",
    "    '3':3,\n",
    "    '4':4,\n",
    "    '5':5,\n",
    "    '6':6,\n",
    "    '7':7,\n",
    "    '8':8,\n",
    "    '9':9,\n",
    "    '10':10,\n",
    "    '11':11,\n",
    "    '12':12,\n",
    "    '13':13,\n",
    "    '14':14,\n",
    "    '15':15,\n",
    "    '16':16,\n",
    "    '17':17,\n",
    "    '18':18,\n",
    "    '19':19,\n",
    "    '20':20}\n",
    "    \n",
    "df['ncond'] = df['ncond'].map(ncond_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4adc3be0-591b-4551-9161-c8ef68ed8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_last_race_mapping = {\n",
    "    '0-14d':1,\n",
    "    '15-30d':2,\n",
    "    '31-60d':3,\n",
    "    '61-90d':4,\n",
    "    '91-180d':5,\n",
    "    '181-365d':6,\n",
    "    '365+d':7 }\n",
    "\n",
    "df['days_since_last_race_binned'] = df['days_since_last_race_binned'].map(days_last_race_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2419f6d6-6c0d-4ebb-beaa-a57d23afcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['saddle_rank_bin'].unique()\n",
    "saddle_rank_bin_mapping = {\n",
    "    '(0.024, 0.143]':1,\n",
    "    '(0.143, 0.25]':2,\n",
    "    '(0.25, 0.333]':3,\n",
    "    '(0.333, 0.444]':4,\n",
    "    '(0.444, 0.55]':5,\n",
    "    '(0.55, 0.647]':6,\n",
    "    '(0.647, 0.75]':7,\n",
    "    '(0.75, 0.846]':8,\n",
    "    '(0.846, 0.944]':9,\n",
    "    '(0.944, 1.0]':10}\n",
    "\n",
    "df['saddle_rank_bin'] = df['saddle_rank_bin'].map(saddle_rank_bin_mapping)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bd411af3-e80d-4f5f-83af-a5bdc30f4cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "import pandas as pd\n",
    "\n",
    "def one_hot_safe(df, col, categories, prefix, drop_first=False, dtype='int8', copy=False):\n",
    "    # optional copy; default False for speed\n",
    "    if copy:\n",
    "        df = df.copy()\n",
    "\n",
    "    # lock category space on the original series (no extra temp DataFrame)\n",
    "    ctype = CategoricalDtype(categories=categories, ordered=False)\n",
    "    s = df[col].astype(ctype)\n",
    "\n",
    "    # build dummies directly with target dtype\n",
    "    dums = pd.get_dummies(s, prefix=prefix, dtype=dtype)\n",
    "\n",
    "    # choose expected columns (handles drop_first without per-column drops)\n",
    "    keep_categories = categories[1:] if drop_first else categories\n",
    "    expected = [f\"{prefix}_{c}\" for c in keep_categories]\n",
    "\n",
    "    # add missing cols & order in one vectorized step (no Python loop)\n",
    "    dums = dums.reindex(columns=expected, fill_value=0)\n",
    "\n",
    "    # concat is a bit faster than join for this use\n",
    "    return pd.concat([df.drop(columns=[col]), dums], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83250fd8-0f68-4db8-96e9-e49cbc22cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_safe(df,'course_surface',['AW', 'Turf', 'Dirt'],'surface')\n",
    "df = one_hot_safe(df,'race_jump_type',['flat', 'hurdles', 'chase'],'jump')\n",
    "\n",
    "df = one_hot_safe(df,'race_age_band',['juvenile', 'open_all', 'mixed', 'open_young', 'young_only',\n",
    "       'veteran', 'unknown'],'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "394e9960-f1af-424c-b59c-43e6b6b6ab44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'distance_banding', 'track_layout']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def has_non_numeric(df, col):\n",
    "    converted = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    non_numeric_found = (converted.isna() & df[col].notna()).any()\n",
    "    \n",
    "    return non_numeric_found\n",
    "def columns_with_non_numeric(df):\n",
    "    return [col for col in df.columns if has_non_numeric(df, col)]\n",
    "\n",
    "print(columns_with_non_numeric(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "40e56aa6-039c-474a-ab32-89fc5f6f4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_layout_mapping = {\n",
    "    'sharp':-1,\n",
    "    'neutral':0,\n",
    "    'galloping':1}\n",
    "\n",
    "df['track_layout'] = df['track_layout'].map(track_layout_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a0275b36-9fff-4ca8-b2c7-b5b72effced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_banding_mapping = {\n",
    "    'short':1,\n",
    "    'medium':2,\n",
    "    'long':3\n",
    "}\n",
    "\n",
    "df['distance_banding'] = df['distance_banding'].map(distance_banding_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6dee1a3c-8a8a-4f3d-b79d-b0808796c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = [\n",
    "    'age',                      # years, but often treated as continuous in regression\n",
    "    'saddle',                   # actual saddle number (weight cloth)\n",
    "    'overWeight',                # extra weight carried\n",
    "    'RPR', 'TR', 'OR',           # ratings                    \n",
    "    'weight',                    # carried weight (numeric measurement)\n",
    "    'distance',                  # race distance\n",
    "    'prize',                     # prize money\n",
    "    'ncond',                     # race condition numeric measure\n",
    "    'racers_per_race',           # size of field (can be treated continuous)\n",
    "    'days_since_last_race',      # days since last run\n",
    "    'saddle_rank_norm',          # continuous version of saddle rank\n",
    "    'band_upper',                # numeric upper value of band          \n",
    "    'rpr_last', 'rpr_mean_last_3', 'rpr_best_last_5', 'rpr_mean_last_20', 'rpr_trend',\n",
    "    'prev_max_rpr', 'prev_rpr_diff_from_top',\n",
    "    'TR_last', 'TR_mean_last_3', 'TR_best_last_5', 'TR_mean_last_20', 'TR_trend',\n",
    "    'diff_TR_RPR_last', 'diff_TR_RPR_last_3',\n",
    "    'prev_max_TR', 'prev_TR_diff_from_top',\n",
    "    'OR_last', 'OR_mean_last_3', 'OR_best_last_5', 'OR_mean_last_20', 'OR_trend',\n",
    "    'diff_OR_RPR_last', 'diff_OR_RPR_last_3',\n",
    "    'prev_max_OR', 'prev_OR_diff_from_top'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b10aa66f-ba81-4dec-b95c-45b83c42de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[continuous_cols] = scaler.fit_transform(df[continuous_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fb8f3629-3b7b-4681-a9c9-7472a051f1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def has_non_numeric(df, col):\n",
    "    converted = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    non_numeric_found = (converted.isna() & df[col].notna()).any()\n",
    "    \n",
    "    return non_numeric_found\n",
    "def columns_with_non_numeric(df):\n",
    "    return [col for col in df.columns if has_non_numeric(df, col)]\n",
    "\n",
    "print(columns_with_non_numeric(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9dc30eee-ed4c-4cb3-a344-f78c8987dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a8bde467-5220-48dd-8232-ce12ed2be044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0009990009990009\n",
      "Max: 0.99009900990099\n",
      "0\n",
      "0\n",
      "1888322\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", df['betting_prob_win'].min())\n",
    "print(\"Max:\", df['betting_prob_win'].max())\n",
    "print(len(df[df['betting_prob_win'] <= 0]))\n",
    "print(len(df[df['betting_prob_win'] > 1]))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "186bfd4b-576c-4b48-bdf4-4f0569227191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prob range: 0.000999 → 0.990099\n",
      "Decimal odds range: 1.01 → 1001.00\n",
      "Max reconstruction diff: 0.00000000\n",
      "✅ Betting prob is consistent with decimal odds.\n"
     ]
    }
   ],
   "source": [
    "def check_betting_prob_consistency(df, prob_col='betting_prob_win', tol=1e-6):\n",
    "    \"\"\"Check if betting_prob_win correctly inverts to decimal odds.\"\"\"\n",
    "    \n",
    "    # Step 1: Convert prob → decimal odds\n",
    "    decimal_odds = 1 / df[prob_col]\n",
    "    \n",
    "    # Step 2: Convert decimal odds back to probability\n",
    "    recon_prob = 1 / decimal_odds\n",
    "    \n",
    "    # Step 3: Compare with original\n",
    "    diff = (df[prob_col] - recon_prob).abs()\n",
    "    max_diff = diff.max()\n",
    "    \n",
    "    print(f\"Original prob range: {df[prob_col].min():.6f} → {df[prob_col].max():.6f}\")\n",
    "    print(f\"Decimal odds range: {decimal_odds.min():.2f} → {decimal_odds.max():.2f}\")\n",
    "    print(f\"Max reconstruction diff: {max_diff:.8f}\")\n",
    "    \n",
    "    if max_diff > tol:\n",
    "        print(\"⚠️ WARNING: Betting prob may not match 1/decimal odds exactly.\")\n",
    "    else:\n",
    "        print(\"✅ Betting prob is consistent with decimal odds.\")\n",
    "\n",
    "# Example usage\n",
    "check_betting_prob_consistency(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "55ec3f9d-b83a-4859-bf14-12f330a9b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/riyaazkhan/Documents/Imperial_Maths/Algorithmic_Trading_Club/Projects/Horse-Racing-Project/Data/LinearRegressionModelData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d50cd-9ea8-41d7-92f6-00c54ff4a68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7c029f2-8b7c-4340-bb7b-0cab8156248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_dates(df, date_col='date', dayfirst=True):\n",
    "    s = df[date_col].astype(str).str.strip()\n",
    "\n",
    "    # 1) Null out common sentinels/placeholders\n",
    "    bad_tokens = {'', 'nan', 'NaN', 'None', '-1', '0', '0000-00-00'}\n",
    "    s = s.mask(s.isin(bad_tokens))\n",
    "\n",
    "    # 2) First pass: general parser\n",
    "    parsed = pd.to_datetime(s, errors='coerce', dayfirst=dayfirst, utc=False)\n",
    "\n",
    "    # 3) Second pass: numeric YYYYMMDD like 20240317\n",
    "    mask_num = parsed.isna() & s.str.fullmatch(r'\\d{8}')\n",
    "    if mask_num.any():\n",
    "        parsed.loc[mask_num] = pd.to_datetime(s[mask_num], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    # Keep only rows with valid dates\n",
    "    keep = ~parsed.isna()\n",
    "    cleaned = df.loc[keep].copy()\n",
    "    cleaned[date_col] = parsed[keep]\n",
    "\n",
    "    dropped = (~keep).sum()\n",
    "    return cleaned, int(dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "485c46cf-35c0-4e7b-b646-53a65b7e7aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with bad dates. Remaining: 1888322\n"
     ]
    }
   ],
   "source": [
    "df, dropped = clean_dates(df, date_col='date', dayfirst=True)\n",
    "print(f\"Dropped {dropped} rows with bad dates. Remaining: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e16dcfa6-8de1-463a-9fba-63e3d3fdb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# === Strict leakage cleaner ===\n",
    "def remove_market_leakage(df, betting_prob_col='betting_prob_win'):\n",
    "    \"\"\"\n",
    "    Remove features that leak market information from the model training set.\n",
    "    Keeps betting_prob_win ONLY for ROI calculation, not as a feature.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Columns to drop: directly derived from market odds\n",
    "    leakage_cols = [\n",
    "        'isFav',                # favourite flag from market\n",
    "        'decimalPrice',         # odds (already in betting_prob_win)\n",
    "        'margin',               # sum of implied probs (market overround)\n",
    "        'fav_rank', 'fav_rank_norm', 'fav_rank_bin',  # favourite rank encoding\n",
    "        'price_diff', 'price_rank',                   # price-based engineered features\n",
    "    ]\n",
    "\n",
    "    # Drop them if present\n",
    "    drop_found = [c for c in leakage_cols if c in df.columns]\n",
    "    if drop_found:\n",
    "        print(f\"[leakage cleaner] Dropping market-derived cols: {drop_found}\")\n",
    "        df = df.drop(columns=drop_found)\n",
    "\n",
    "    if betting_prob_col not in df.columns:\n",
    "        raise ValueError(f\"{betting_prob_col} is missing from dataframe!\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# === Backtest function ===\n",
    "def backtest_exclude_market_use_as_benchmark(\n",
    "    df,\n",
    "    target_col='res_win',\n",
    "    date_col='date',\n",
    "    race_id_col=None,\n",
    "    prob_col='betting_prob_win',\n",
    "    test_fraction=0.2,\n",
    "    edge_rel=0.15,\n",
    "    min_book_p=0.01, max_book_p=0.99,\n",
    "    random_state=42,\n",
    "    sgd_max_iter=30, sgd_tol=1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    Train on *all numeric, non-market* features only.\n",
    "    Use bookmaker probability ONLY to decide/place bets and settle with 1/book_p odds.\n",
    "    \"\"\"\n",
    "    # 1) Remove leakage columns\n",
    "    d = remove_market_leakage(df, betting_prob_col=prob_col)\n",
    "\n",
    "    # 2) Dates: keep only parsed & not in the future\n",
    "    d[date_col] = pd.to_datetime(d[date_col], errors='coerce')\n",
    "    d = d.dropna(subset=[date_col])\n",
    "    d = d[d[date_col] <= pd.Timestamp(date.today())]\n",
    "\n",
    "    # 3) Clean bookmaker probs\n",
    "    book_p = pd.to_numeric(d[prob_col], errors='coerce')\n",
    "    if book_p.max(skipna=True) and 1 < book_p.max() <= 100:\n",
    "        book_p = book_p / 100.0\n",
    "    book_p = book_p.replace([np.inf, -np.inf], np.nan).clip(min_book_p, max_book_p)\n",
    "    d = d.assign(_book_p=book_p).dropna(subset=['_book_p', target_col])\n",
    "\n",
    "    # 4) Chronological split\n",
    "    d = d.sort_values(date_col).reset_index(drop=True)\n",
    "    split_idx = int(len(d) * (1 - test_fraction))\n",
    "    train_df = d.iloc[:split_idx].copy()\n",
    "    test_df  = d.iloc[split_idx:].copy()\n",
    "\n",
    "    # 5) Optional: forbid race overlap\n",
    "    if race_id_col and race_id_col in d.columns:\n",
    "        seen = set(train_df[race_id_col])\n",
    "        test_df = test_df[~test_df[race_id_col].isin(seen)].copy()\n",
    "\n",
    "    # 6) Feature selection: numeric only, excluding market + target/date/race_id\n",
    "    exclude = {target_col, prob_col, '_book_p', date_col}\n",
    "    if race_id_col: exclude.add(race_id_col)\n",
    "    numeric_cols = d.select_dtypes(include=['number', 'bool']).columns.tolist()\n",
    "    feature_cols = [c for c in numeric_cols if c not in exclude]\n",
    "    if not feature_cols:\n",
    "        raise ValueError(\"No numeric features left after excluding market + target/date/race_id.\")\n",
    "\n",
    "    # 7) Train/test matrices\n",
    "    X_train = train_df[feature_cols].astype(np.float32)\n",
    "    y_train = train_df[target_col].astype(int).to_numpy()\n",
    "    X_test  = test_df[feature_cols].astype(np.float32)\n",
    "    y_test  = test_df[target_col].astype(int).to_numpy()\n",
    "\n",
    "    # Market (for betting only)\n",
    "    book_p  = test_df['_book_p'].to_numpy(np.float64)\n",
    "    odds    = 1.0 / book_p\n",
    "    assert np.all((book_p > 0) & (book_p < 1)) and np.all(odds >= 1.0)\n",
    "\n",
    "    # 8) Model training\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        SGDClassifier(loss='log_loss', penalty='l2',\n",
    "                      max_iter=sgd_max_iter, tol=sgd_tol,\n",
    "                      early_stopping=True, n_iter_no_change=3,\n",
    "                      validation_fraction=0.1, random_state=random_state)\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    model_p = np.clip(model.predict_proba(X_test)[:, 1], 0.0, 1.0)\n",
    "\n",
    "    # 9) Bet rule\n",
    "    bet_mask = model_p > (book_p * (1.0 + edge_rel))\n",
    "    profit_each = np.where(bet_mask, np.where(y_test == 1, odds - 1.0, -1.0), 0.0)\n",
    "\n",
    "    # 10) Metrics\n",
    "    brier = mean_squared_error(y_test, model_p)\n",
    "    n_test = len(y_test)\n",
    "    n_bets = int(bet_mask.sum())\n",
    "    total_profit = float(np.nansum(profit_each))\n",
    "    roi = total_profit / n_bets if n_bets else 0.0\n",
    "\n",
    "    real_win_rate_on_bets = y_test[bet_mask].mean() if n_bets else 0.0\n",
    "    book_win_rate_on_bets = book_p[bet_mask].mean() if n_bets else 0.0\n",
    "    rnd_wins = (np.random.default_rng(random_state).random(n_test) < book_p)\n",
    "    rnd_profit = np.where(bet_mask, np.where(rnd_wins, odds - 1.0, -1.0), 0.0)\n",
    "    rnd_roi = rnd_profit[bet_mask].mean() if n_bets else 0.0\n",
    "\n",
    "    print(f\"Train: {train_df[date_col].min().date()} → {train_df[date_col].max().date()}\")\n",
    "    print(f\"Test : {test_df[date_col].min().date()} → {test_df[date_col].max().date()}  (rows={n_test})\")\n",
    "    print(f\"Features used: {len(feature_cols)} (market excluded)\")\n",
    "    print(f\"Brier={brier:.4f} | Bets={n_bets} ({n_bets/n_test*100:.2f}%) | Profit=£{total_profit:.2f} | ROI/bet=£{roi:.3f}\")\n",
    "    print(f\"Win%% on bets (real vs book): {real_win_rate_on_bets:.3f} vs {book_win_rate_on_bets:.3f}\")\n",
    "    print(f\"Random-by-book_p ROI/bet (sanity): {rnd_roi:.4f}\")\n",
    "\n",
    "    summary = {\n",
    "        \"brier\": brier,\n",
    "        \"bets\": n_bets,\n",
    "        \"bets_pct\": (n_bets / n_test * 100.0) if n_test else 0.0,\n",
    "        \"total_profit\": total_profit,\n",
    "        \"roi_per_bet\": roi,\n",
    "        \"real_win_rate_on_bets\": real_win_rate_on_bets,\n",
    "        \"book_win_rate_on_bets\": book_win_rate_on_bets,\n",
    "        \"rnd_roi_by_book\": rnd_roi,\n",
    "        \"n_features\": len(feature_cols)\n",
    "    }\n",
    "\n",
    "    details = pd.DataFrame({\n",
    "        \"y_true\": y_test,\n",
    "        \"model_prob\": model_p,\n",
    "        \"book_prob\": book_p,\n",
    "        \"decimal_odds\": odds,\n",
    "        \"bet\": bet_mask.astype(int),\n",
    "        \"profit\": profit_each\n",
    "    }, index=test_df.index)\n",
    "\n",
    "    return model, summary, details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "06d3e45f-0ea1-4fa1-8aa7-fb9bc0c26027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[leakage cleaner] Dropping market-derived cols: ['isFav']\n",
      "Train: 1997-01-01 → 2020-02-10\n",
      "Test : 2020-02-10 → 2025-08-10  (rows=307215)\n",
      "Features used: 126 (market excluded)\n",
      "Brier=0.0661 | Bets=89919 (29.27%) | Profit=£62595.61 | ROI/bet=£0.696\n",
      "Win%% on bets (real vs book): 0.177 vs 0.096\n",
      "Random-by-book_p ROI/bet (sanity): 0.0044\n"
     ]
    }
   ],
   "source": [
    "model, summary, details = backtest_exclude_market_use_as_benchmark(\n",
    "    df,\n",
    "    target_col='res_win',\n",
    "    date_col='date',\n",
    "    race_id_col='race_id',          # if you have it\n",
    "    prob_col='betting_prob_win',\n",
    "    test_fraction=0.2,\n",
    "    edge_rel=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7317e30-c03b-4bf8-883c-04949b15488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "aa787094-dbf7-406a-a8b5-e3f1aaa18eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def drop_market_leakage_strict(df, target_col, date_col, betting_prob_col, test_fraction=0.2, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Detect and drop features that leak market info by correlating with betting_prob_win.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with all races\n",
    "        target_col: str, target column name\n",
    "        date_col: str, race date column\n",
    "        betting_prob_col: str, market win probability column\n",
    "        test_fraction: float, fraction for time-based test split\n",
    "        threshold: float, absolute correlation threshold for dropping features\n",
    "    Returns:\n",
    "        cleaned_df, dropped_features\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    d[date_col] = pd.to_datetime(d[date_col], errors='coerce')\n",
    "    d = d.dropna(subset=[date_col, betting_prob_col, target_col])\n",
    "    d = d.sort_values(date_col).reset_index(drop=True)\n",
    "\n",
    "    # Split train/test by time\n",
    "    split_idx = int(len(d) * (1 - test_fraction))\n",
    "    test_df = d.iloc[split_idx:]\n",
    "\n",
    "    # Only numeric columns for correlation check\n",
    "    num_cols = [c for c in d.select_dtypes(include=[np.number]).columns\n",
    "                if c not in [target_col, betting_prob_col]]\n",
    "\n",
    "    # Correlation with market prob in test set\n",
    "    corr_series = test_df[num_cols].corrwith(test_df[betting_prob_col])\n",
    "    leak_feats = corr_series[abs(corr_series) > threshold].index.tolist()\n",
    "\n",
    "    print(f\"Detected {len(leak_feats)} possible leakage features (|corr| > {threshold}):\")\n",
    "    for f in leak_feats:\n",
    "        print(f\"  {f} (corr={corr_series[f]:.4f})\")\n",
    "\n",
    "    # Drop them\n",
    "    cleaned_df = d.drop(columns=leak_feats)\n",
    "\n",
    "    return cleaned_df, leak_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "95bb7932-df85-4723-a4f5-579b23549f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 38 possible leakage features (|corr| > 0.05):\n",
      "  saddle (corr=-0.2615)\n",
      "  isFav (corr=0.7078)\n",
      "  outHandicap (corr=-0.0734)\n",
      "  RPR (corr=0.2663)\n",
      "  TR (corr=0.1948)\n",
      "  OR (corr=0.0828)\n",
      "  weight (corr=0.0552)\n",
      "  racers_per_race (corr=-0.2809)\n",
      "  days_since_last_race (corr=-0.0520)\n",
      "  saddle_rank (corr=-0.2657)\n",
      "  saddle_rank_norm (corr=-0.1387)\n",
      "  saddle_rank_bin (corr=-0.1513)\n",
      "  trainer_win_encoded (corr=0.2733)\n",
      "  jockey_win_encoded (corr=0.2824)\n",
      "  horse_win_encoded (corr=0.2059)\n",
      "  rpr_last (corr=0.1764)\n",
      "  rpr_trend (corr=0.1112)\n",
      "  prev_max_rpr (corr=0.0657)\n",
      "  prev_rpr_diff_from_top (corr=0.0977)\n",
      "  TR_last (corr=0.1407)\n",
      "  TR_trend (corr=0.0598)\n",
      "  diff_TR_RPR_last (corr=-0.0702)\n",
      "  prev_max_TR (corr=0.0534)\n",
      "  OR_last (corr=0.0860)\n",
      "  OR_trend (corr=0.0640)\n",
      "  prev_OR_diff_from_top (corr=0.0710)\n",
      "  saddle_nan (corr=0.0586)\n",
      "  outHandicap_nan (corr=0.0783)\n",
      "  RPR_nan (corr=-0.0973)\n",
      "  TR_nan (corr=-0.1078)\n",
      "  saddle_rank_nan (corr=0.0586)\n",
      "  saddle_rank_norm_nan (corr=0.0586)\n",
      "  saddle_rank_bin_nan (corr=0.0586)\n",
      "  rpr_last_nan (corr=-0.0633)\n",
      "  prev_rpr_diff_from_top_nan (corr=-0.0633)\n",
      "  TR_last_nan (corr=-0.0766)\n",
      "  diff_TR_RPR_last_nan (corr=-0.0771)\n",
      "  prev_TR_diff_from_top_nan (corr=-0.0766)\n",
      "\n",
      "Remaining features: 92\n",
      "Dropped features: ['saddle', 'isFav', 'outHandicap', 'RPR', 'TR', 'OR', 'weight', 'racers_per_race', 'days_since_last_race', 'saddle_rank', 'saddle_rank_norm', 'saddle_rank_bin', 'trainer_win_encoded', 'jockey_win_encoded', 'horse_win_encoded', 'rpr_last', 'rpr_trend', 'prev_max_rpr', 'prev_rpr_diff_from_top', 'TR_last', 'TR_trend', 'diff_TR_RPR_last', 'prev_max_TR', 'OR_last', 'OR_trend', 'prev_OR_diff_from_top', 'saddle_nan', 'outHandicap_nan', 'RPR_nan', 'TR_nan', 'saddle_rank_nan', 'saddle_rank_norm_nan', 'saddle_rank_bin_nan', 'rpr_last_nan', 'prev_rpr_diff_from_top_nan', 'TR_last_nan', 'diff_TR_RPR_last_nan', 'prev_TR_diff_from_top_nan']\n"
     ]
    }
   ],
   "source": [
    "df_clean, dropped = drop_market_leakage_strict(\n",
    "    df,\n",
    "    target_col='res_win',\n",
    "    date_col='date',\n",
    "    betting_prob_col='betting_prob_win',\n",
    "    test_fraction=0.2,\n",
    "    threshold=0.05  # strict\n",
    ")\n",
    "\n",
    "print(f\"\\nRemaining features: {len(df_clean.columns)}\")\n",
    "print(f\"Dropped features: {dropped}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad56fe33-31a1-47dc-b4d0-3ba4958d859e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
